{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0joX5fpxdM7"
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "\n",
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "tS05nCktGbSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8eb92e-bc21-41c5-b065-ff7ea6296102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Collecting accelerate>=0.20.3 (from transformers[torch])\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.24.1\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg    # download en_core_web_lg model"
      ],
      "metadata": {
        "id": "HJCw_ZAdQg3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac44440e-46fe-4aab-8ea1-895c34c5a2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-01 06:41:53.836937: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-01 06:41:53.836995: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-01 06:41:53.837044: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-01 06:41:53.845145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-01 06:41:55.685756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-01 06:41:58.422150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-01 06:41:58.422797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-01 06:41:58.423001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Collecting en-core-web-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.6.0/en_core_web_lg-3.6.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "A7SU2W0ZxnNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a33488a-f465-4380-a0eb-02feb690f885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as before\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import datasets\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "\n",
        "from tabulate import tabulate\n",
        "import nltk\n",
        "from datetime import datetime\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "TMWqPd7pydME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "GbKN-0XCV6Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as before\n",
        "\n",
        "def entity_based_filtered_sentences(text,summary):\n",
        "    doc = nlp(summary)\n",
        "    sentences_select = {}\n",
        "    for sent in doc.sents:\n",
        "        sentences_select[sent.text] = True\n",
        "    for e in doc.ents:\n",
        "        if e[0].ent_type_ in ['PERSON', 'FAC', 'GPE', 'ORG', 'NORP', 'LOC', 'EVENT']:\n",
        "            if e.text.lower() not in text.lower():\n",
        "                sentences_select[e.sent.text] = False\n",
        "    result = []\n",
        "    for sent in doc.sents:\n",
        "        if sentences_select[sent.text]:\n",
        "            result.append(sent.text)\n",
        "    filter_summary =  \" \".join(result)\n",
        "    return filter_summary\n",
        "\n",
        "def create_ent_augmented_target(text,summary):\n",
        "    entity_summary = []\n",
        "    doc = nlp(summary)\n",
        "    entities = []\n",
        "    for e in doc.ents:\n",
        "        if e[0].ent_type_ in ['PERSON', 'FAC', 'GPE', 'ORG', 'NORP', 'LOC', 'EVENT']:\n",
        "            if e.text.lower() in text.lower():\n",
        "                entities.append(e.text)\n",
        "\n",
        "    entity_summary =  \" \".join(entities)\n",
        "    entity_summary = entity_summary + \" \" + summary\n",
        "    return entity_summary"
      ],
      "metadata": {
        "id": "kBpFdkF08fcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the saved model from the filtered data\n",
        "\n",
        "!unzip -q '/content/drive/MyDrive/AML Project/finetune_cnn_dm_filtered.zip'"
      ],
      "metadata": {
        "id": "daaRx3zjTqt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/content/finetune_cnn_dm_filtered'\n",
        "model_name_summ = path\n",
        "\n",
        "model_summ = AutoModelForSeq2SeqLM.from_pretrained(model_name_summ)\n",
        "tokenizer_summ = AutoTokenizer.from_pretrained(model_name_summ)"
      ],
      "metadata": {
        "id": "f87sc0Bfygrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as before\n",
        "\n",
        "def generate_summary(test_samples, model):\n",
        "    inputs = tokenizer_summ(\n",
        "        test_samples,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "    outputs = model_summ.generate(input_ids, attention_mask=attention_mask)\n",
        "    output_str = tokenizer_summ.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return output_str"
      ],
      "metadata": {
        "id": "qpAao3Up1ap1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "\n",
        "from transformers import T5ForConditionalGeneration, T5TokenizerFast, AutoModelForSeq2SeqLM\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "model_name_qa = \"deepset/roberta-base-squad2\"                                             # Pre defined model for question and answer\n",
        "model_qa = AutoModelForQuestionAnswering.from_pretrained(model_name_qa)\n",
        "tokenizer_qa = AutoTokenizer.from_pretrained(model_name_qa)\n",
        "nlp_qa = pipeline('question-answering', model=model_name_qa, tokenizer_qa=model_name_qa)\n",
        "\n",
        "hfmodel = T5ForConditionalGeneration.from_pretrained(\"ThomasSimonini/t5-end2end-question-generation\")\n",
        "hftokenizer = T5TokenizerFast.from_pretrained('t5-base')"
      ],
      "metadata": {
        "id": "IQTKGDE34Cg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate question\n",
        "\n",
        "def gen_question(input_string, **generator_args):\n",
        "  generator_args = {                                                            # Defining the parameters of question generation\n",
        "  \"max_length\": 256,\n",
        "  \"num_beams\": 1,\n",
        "  \"length_penalty\": 1.5,\n",
        "  \"no_repeat_ngram_size\": 3,\n",
        "  \"early_stopping\": True,\n",
        "  }\n",
        "  input_string = \"generate questions: \" + input_string + \" </s>\"                  # Making input string\n",
        "  input_ids = hftokenizer.encode(input_string, truncation=True, return_tensors=\"pt\")  # Input encoding\n",
        "  res = hfmodel.generate(input_ids, **generator_args)                               # Generate result\n",
        "  output = hftokenizer.batch_decode(res, skip_special_tokens=True)                  # Get the final output\n",
        "  output = [item.split(\"<sep>\") for item in output]                                 # Stripping the output\n",
        "  return output"
      ],
      "metadata": {
        "id": "suqket2i4Gy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate answers\n",
        "\n",
        "def gen_answers(doc, summ):\n",
        "  ques = gen_question(doc)                                                      # First generate question from doc\n",
        "  ans = []\n",
        "  for _ in ques[0][0].split('? '):\n",
        "    doc_ans = nlp_qa({'question': _+'?', 'context': doc})['answer']             # Answer from doc\n",
        "    summ_ans = nlp_qa({'question': _+'?', 'context': summ})['answer']           # Answer from summary\n",
        "    ans.append((doc_ans, summ_ans))\n",
        "  return ques, ans"
      ],
      "metadata": {
        "id": "uG3TZ-Xy4HR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo for question answering\n",
        "\n",
        "def Demo(text):\n",
        "  summ = generate_summary(text, model_summ)[0]                                  # First generate summary\n",
        "  print(\"Summary:\", summ)\n",
        "  q, a = gen_answers(text, summ)                                                # Generate question and answers from text and summary\n",
        "  print(\"Questions:\", q)\n",
        "  print(\"Answers:\", a)\n",
        "  return"
      ],
      "metadata": {
        "id": "1ewEB7Dx1Jl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo for summarization\n",
        "\n",
        "def Demo_FJ(text, summary):\n",
        "  filtered = entity_based_filtered_sentences(text,summary)                      # Generate filtered data\n",
        "  JAENS = create_ent_augmented_target(text,summary)                             # Generates JAENS data\n",
        "  jf = create_ent_augmented_target(text, filtered)                              # Generates JAENS data from filtered data\n",
        "  print(\"Filtered summary:\\n\", filtered)\n",
        "  print(\"JAENS summary:\\n\", JAENS)\n",
        "  print(\"Filter+JAENS:\\n\", jf)\n",
        "  return"
      ],
      "metadata": {
        "id": "eS1p2ZDG-akz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results from a sample text for q and a\n",
        "\n",
        "text = \"The telescreen received and transmitted simultaneously. Any sound that Winston made, above the level of a very low whisper, would be picked up by it, moreover, so long as he remained within the field of vision which the metal plaque commanded, he could be seen as well as heard. There was of course no way of knowing whether you were being watched at any given moment. How often, or on what system, the Thought Police plugged in on any individual wire was guesswork. It was even conceivable that they watched everybody all the time. But at any rate, they could plug in your wire whenever they wanted to. You had to live—did live, from habit that became instinct—in the assumption that every sound you made was overheard, and, except in darkness, every movement scrutinized.\"\n",
        "print(\"Article:\", text)\n",
        "summary = \"In Winston's world, the telescreen functioned as both a receiver and transmitter, capturing any sound above a whisper and allowing him to be seen within its field of vision. The pervasive uncertainty of being watched by the Thought Police meant living with the constant assumption that all sounds were overheard and every movement, except in darkness, was scrutinized.\"\n",
        "print(\"Highlights:\", summary)\n",
        "Demo(text)"
      ],
      "metadata": {
        "id": "nSPsB2so1aC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178d641c-1436-4bf2-a0b4-8d125857594b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article: The telescreen received and transmitted simultaneously. Any sound that Winston made, above the level of a very low whisper, would be picked up by it, moreover, so long as he remained within the field of vision which the metal plaque commanded, he could be seen as well as heard. There was of course no way of knowing whether you were being watched at any given moment. How often, or on what system, the Thought Police plugged in on any individual wire was guesswork. It was even conceivable that they watched everybody all the time. But at any rate, they could plug in your wire whenever they wanted to. You had to live—did live, from habit that became instinct—in the assumption that every sound you made was overheard, and, except in darkness, every movement scrutinized.\n",
            "Highlights: In Winston's world, the telescreen functioned as both a receiver and transmitter, capturing any sound above a whisper and allowing him to be seen within its field of vision. The pervasive uncertainty of being watched by the Thought Police meant living with the constant assumption that all sounds were overheard and every movement, except in darkness, was scrutinized.\n",
            "Summary: the Thought Police The Thought Police plugged in any individual wire whenever they wanted to.\n",
            "\n",
            "Questions: [[\"What was the telescreen capable of? What was Winston's condition? How often did the Thought Police plug in on any individual wire?\"]]\n",
            "Answers: [('received and transmitted simultaneously', 'plugged in any individual wire'), ('so long as he remained within the field of vision', 'plugged in any individual wire'), ('whenever they wanted to', 'whenever they wanted to')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results from a sample text for different summaries by different filtering\n",
        "\n",
        "print(\"True summary:\\n\", summary)\n",
        "Demo_FJ(text, summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paTfE32YWApV",
        "outputId": "0e2ed35b-4593-4732-83bf-f5554e9e12f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True summary:\n",
            " In Winston's world, the telescreen functioned as both a receiver and transmitter, capturing any sound above a whisper and allowing him to be seen within its field of vision. The pervasive uncertainty of being watched by the Thought Police meant living with the constant assumption that all sounds were overheard and every movement, except in darkness, was scrutinized.\n",
            "Filtered summary:\n",
            " In Winston's world, the telescreen functioned as both a receiver and transmitter, capturing any sound above a whisper and allowing him to be seen within its field of vision. The pervasive uncertainty of being watched by the Thought Police meant living with the constant assumption that all sounds were overheard and every movement, except in darkness, was scrutinized.\n",
            "JAENS summary:\n",
            " Winston the Thought Police In Winston's world, the telescreen functioned as both a receiver and transmitter, capturing any sound above a whisper and allowing him to be seen within its field of vision. The pervasive uncertainty of being watched by the Thought Police meant living with the constant assumption that all sounds were overheard and every movement, except in darkness, was scrutinized.\n",
            "Filter+JAENS:\n",
            " Winston the Thought Police In Winston's world, the telescreen functioned as both a receiver and transmitter, capturing any sound above a whisper and allowing him to be seen within its field of vision. The pervasive uncertainty of being watched by the Thought Police meant living with the constant assumption that all sounds were overheard and every movement, except in darkness, was scrutinized.\n"
          ]
        }
      ]
    }
  ]
}